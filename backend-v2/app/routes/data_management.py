"""
ðŸŒ± ë°ì´í„° ê´€ë¦¬ ë¼ìš°íŠ¸
í”„ë¡ íŠ¸ì—”ë“œ 'ë°ì´í„° ê´€ë¦¬' íƒ­ ì™„ì „ ëŒ€ì‘
"""

from flask import Blueprint, request, jsonify, make_response
from datetime import datetime, timedelta
import json
import csv
import io
from app.models.plant import AnalysisResult, EnvironmentData, PlantImage
from app import db

data_management_bp = Blueprint('data_management', __name__, url_prefix='/api/v2/data-management')

@data_management_bp.route('/export/json', methods=['POST'])
def export_json():
    """JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
    try:
        data = request.get_json()
        export_type = data.get('type', 'all')
        date_range = data.get('dateRange', {})
        
        export_data = {}
        
        # ë‚ ì§œ í•„í„°ë§ ì„¤ì •
        start_date = None
        end_date = None
        if date_range.get('start'):
            start_date = datetime.fromisoformat(date_range['start'])
        if date_range.get('end'):
            end_date = datetime.fromisoformat(date_range['end'])
        
        # ë¶„ì„ ê²°ê³¼ ë°ì´í„°
        if export_type in ['all', 'analysis']:
            query = AnalysisResult.query
            if start_date:
                query = query.filter(AnalysisResult.date >= start_date)
            if end_date:
                query = query.filter(AnalysisResult.date <= end_date)
            
            analysis_results = query.order_by(AnalysisResult.date.desc()).all()
            export_data['analysis_results'] = [result.to_dict() for result in analysis_results]
        
        # í™˜ê²½ ë°ì´í„°
        if export_type in ['all', 'environment']:
            query = EnvironmentData.query
            if start_date:
                query = query.filter(EnvironmentData.timestamp >= start_date)
            if end_date:
                query = query.filter(EnvironmentData.timestamp <= end_date)
            
            env_data = query.order_by(EnvironmentData.timestamp.desc()).all()
            export_data['environment_data'] = [data.to_dict() for data in env_data]
        
        # ì´ë¯¸ì§€ ë°ì´í„°
        if export_type in ['all', 'images']:
            query = PlantImage.query
            if start_date:
                query = query.filter(PlantImage.timestamp >= start_date)
            if end_date:
                query = query.filter(PlantImage.timestamp <= end_date)
            
            images = query.order_by(PlantImage.timestamp.desc()).all()
            export_data['images'] = [img.to_dict() for img in images]
        
        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        export_data['metadata'] = {
            'export_timestamp': datetime.now().isoformat(),
            'export_type': export_type,
            'date_range': date_range,
            'total_records': sum(len(v) for v in export_data.values() if isinstance(v, list))
        }
        
        # JSON ì‘ë‹µ ìƒì„±
        response = make_response(json.dumps(export_data, ensure_ascii=False, indent=2))
        response.headers['Content-Type'] = 'application/json; charset=utf-8'
        response.headers['Content-Disposition'] = f'attachment; filename=smartfarm_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        
        return response
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'JSON ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}'
        }), 500

@data_management_bp.route('/export/csv', methods=['POST'])
def export_csv():
    """CSV í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
    try:
        data = request.get_json()
        export_type = data.get('type', 'analysis')
        date_range = data.get('dateRange', {})
        
        # CSV ë°ì´í„° ìƒì„±
        output = io.StringIO()
        
        if export_type == 'analysis':
            # ë¶„ì„ ê²°ê³¼ CSV
            writer = csv.writer(output)
            writer.writerow(['ID', 'ëª¨ë¸ID', 'ë¶„ì„ì¼ì‹œ', 'ìƒíƒœ', 'ì‹ ë¢°ë„', 'ê¶Œìž¥ì‚¬í•­'])
            
            query = AnalysisResult.query
            if date_range.get('start'):
                start_date = datetime.fromisoformat(date_range['start'])
                query = query.filter(AnalysisResult.date >= start_date)
            if date_range.get('end'):
                end_date = datetime.fromisoformat(date_range['end'])
                query = query.filter(AnalysisResult.date <= end_date)
            
            results = query.order_by(AnalysisResult.date.desc()).all()
            for result in results:
                recommendations = json.loads(result.recommendations) if result.recommendations else []
                writer.writerow([
                    result.id,
                    result.model_id,
                    result.date.isoformat() if result.date else '',
                    result.condition or '',
                    '',  # ì‹ ë¢°ë„ëŠ” analysis_dataì—ì„œ ì¶”ì¶œ í•„ìš”
                    '; '.join(recommendations)
                ])
        
        elif export_type == 'environment':
            # í™˜ê²½ ë°ì´í„° CSV
            writer = csv.writer(output)
            writer.writerow(['ID', 'ì¸¡ì •ì‹œê°„', 'ë‚´ë¶€ì˜¨ë„', 'ì™¸ë¶€ì˜¨ë„', 'ê·¼ê¶Œì˜¨ë„', 'ë‚´ë¶€ìŠµë„', 'ì¼ì‚¬ëŸ‰', 'pH', 'EC', 'ìš©ì¡´ì‚°ì†Œ'])
            
            query = EnvironmentData.query
            if date_range.get('start'):
                start_date = datetime.fromisoformat(date_range['start'])
                query = query.filter(EnvironmentData.timestamp >= start_date)
            if date_range.get('end'):
                end_date = datetime.fromisoformat(date_range['end'])
                query = query.filter(EnvironmentData.timestamp <= end_date)
            
            env_data = query.order_by(EnvironmentData.timestamp.desc()).all()
            for data in env_data:
                writer.writerow([
                    data.id,
                    data.timestamp.isoformat() if data.timestamp else '',
                    data.inner_temperature,
                    data.outer_temperature,
                    data.root_zone_temperature,
                    data.inner_humidity,
                    data.solar_radiation,
                    data.ph,
                    data.ec,
                    data.dissolved_oxygen
                ])
        
        # CSV ì‘ë‹µ ìƒì„±
        csv_data = output.getvalue()
        output.close()
        
        response = make_response(csv_data)
        response.headers['Content-Type'] = 'text/csv; charset=utf-8'
        response.headers['Content-Disposition'] = f'attachment; filename=smartfarm_{export_type}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        
        return response
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'CSV ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {str(e)}'
        }), 500

@data_management_bp.route('/import', methods=['POST'])
def import_data():
    """ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        if 'file' not in request.files:
            return jsonify({
                'status': 'error',
                'message': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'
            }), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({
                'status': 'error',
                'message': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'
            }), 400
        
        # íŒŒì¼ í˜•ì‹ í™•ì¸
        if not file.filename.lower().endswith(('.json', '.csv')):
            return jsonify({
                'status': 'error',
                'message': 'JSON ë˜ëŠ” CSV íŒŒì¼ë§Œ ì§€ì›ë©ë‹ˆë‹¤'
            }), 400
        
        import_results = {
            'total_records': 0,
            'successful_imports': 0,
            'failed_imports': 0,
            'errors': []
        }
        
        if file.filename.lower().endswith('.json'):
            # JSON íŒŒì¼ ì²˜ë¦¬
            try:
                file_content = file.read().decode('utf-8')
                data = json.loads(file_content)
                
                # í™˜ê²½ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                if 'environment_data' in data:
                    for env_record in data['environment_data']:
                        try:
                            env_data = EnvironmentData(
                                inner_temperature=float(env_record['innerTemperature']),
                                outer_temperature=float(env_record['outerTemperature']),
                                root_zone_temperature=float(env_record['rootZoneTemperature']),
                                inner_humidity=float(env_record['innerHumidity']),
                                solar_radiation=float(env_record['solarRadiation']),
                                ph=float(env_record['ph']),
                                ec=float(env_record['ec']),
                                dissolved_oxygen=float(env_record['dissolvedOxygen']),
                                timestamp=datetime.fromisoformat(env_record['timestamp']) if env_record.get('timestamp') else datetime.now()
                            )
                            db.session.add(env_data)
                            import_results['successful_imports'] += 1
                        except Exception as e:
                            import_results['failed_imports'] += 1
                            import_results['errors'].append(f'í™˜ê²½ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}')
                        
                        import_results['total_records'] += 1
                
                db.session.commit()
                
            except json.JSONDecodeError:
                return jsonify({
                    'status': 'error',
                    'message': 'ìœ íš¨í•˜ì§€ ì•Šì€ JSON íŒŒì¼ìž…ë‹ˆë‹¤'
                }), 400
        
        elif file.filename.lower().endswith('.csv'):
            # CSV íŒŒì¼ ì²˜ë¦¬
            try:
                file_content = file.read().decode('utf-8')
                csv_reader = csv.DictReader(io.StringIO(file_content))
                
                for row in csv_reader:
                    try:
                        # CSV í—¤ë”ì— ë”°ë¼ ì ì ˆí•œ ë°ì´í„° ëª¨ë¸ë¡œ ë³€í™˜
                        if 'ë‚´ë¶€ì˜¨ë„' in row:  # í™˜ê²½ ë°ì´í„°
                            env_data = EnvironmentData(
                                inner_temperature=float(row['ë‚´ë¶€ì˜¨ë„']),
                                outer_temperature=float(row['ì™¸ë¶€ì˜¨ë„']),
                                root_zone_temperature=float(row['ê·¼ê¶Œì˜¨ë„']),
                                inner_humidity=float(row['ë‚´ë¶€ìŠµë„']),
                                solar_radiation=float(row['ì¼ì‚¬ëŸ‰']),
                                ph=float(row['pH']),
                                ec=float(row['EC']),
                                dissolved_oxygen=float(row['ìš©ì¡´ì‚°ì†Œ']),
                                timestamp=datetime.fromisoformat(row['ì¸¡ì •ì‹œê°„']) if row.get('ì¸¡ì •ì‹œê°„') else datetime.now()
                            )
                            db.session.add(env_data)
                        
                        import_results['successful_imports'] += 1
                    except Exception as e:
                        import_results['failed_imports'] += 1
                        import_results['errors'].append(f'CSV í–‰ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}')
                    
                    import_results['total_records'] += 1
                
                db.session.commit()
                
            except Exception as e:
                return jsonify({
                    'status': 'error',
                    'message': f'CSV íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}'
                }), 400
        
        return jsonify({
            'status': 'success',
            'message': 'ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ',
            'data': import_results
        }), 200
        
    except Exception as e:
        db.session.rollback()
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}'
        }), 500

@data_management_bp.route('/storage/info', methods=['GET'])
def get_storage_info():
    """ìŠ¤í† ë¦¬ì§€ ì •ë³´ ì¡°íšŒ"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
        analysis_count = AnalysisResult.query.count()
        environment_count = EnvironmentData.query.count()
        image_count = PlantImage.query.count()
        
        # íŒŒì¼ í¬ê¸° ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
        import random
        estimated_db_size = (analysis_count * 2 + environment_count * 1 + image_count * 0.5) * 1024  # KB
        estimated_file_size = image_count * random.randint(1000, 5000)  # KB
        
        storage_info = {
            'database': {
                'analysis_results': analysis_count,
                'environment_data': environment_count,
                'images_metadata': image_count,
                'estimated_size_kb': int(estimated_db_size)
            },
            'files': {
                'image_files': image_count,
                'estimated_size_kb': int(estimated_file_size)
            },
            'total': {
                'records': analysis_count + environment_count + image_count,
                'estimated_size_mb': round((estimated_db_size + estimated_file_size) / 1024, 2)
            },
            'last_updated': datetime.now().isoformat()
        }
        
        return jsonify({
            'status': 'success',
            'message': 'ìŠ¤í† ë¦¬ì§€ ì •ë³´ ì¡°íšŒ ì™„ë£Œ',
            'data': storage_info
        }), 200
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ìŠ¤í† ë¦¬ì§€ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}'
        }), 500

@data_management_bp.route('/cleanup', methods=['POST'])
def cleanup_data():
    """ë°ì´í„° ì •ë¦¬"""
    try:
        data = request.get_json()
        cleanup_type = data.get('type', 'old_data')
        days_old = data.get('daysOld', 30)
        
        cleanup_results = {
            'deleted_records': 0,
            'freed_space_kb': 0,
            'cleanup_type': cleanup_type
        }
        
        cutoff_date = datetime.now() - timedelta(days=days_old)
        
        if cleanup_type == 'old_data':
            # ì˜¤ëž˜ëœ ë°ì´í„° ì‚­ì œ
            old_analysis = AnalysisResult.query.filter(AnalysisResult.date < cutoff_date).all()
            old_environment = EnvironmentData.query.filter(EnvironmentData.timestamp < cutoff_date).all()
            
            for record in old_analysis:
                db.session.delete(record)
                cleanup_results['deleted_records'] += 1
            
            for record in old_environment:
                db.session.delete(record)
                cleanup_results['deleted_records'] += 1
        
        elif cleanup_type == 'failed_analysis':
            # ì‹¤íŒ¨í•œ ë¶„ì„ ê²°ê³¼ ì‚­ì œ
            failed_analysis = AnalysisResult.query.filter(
                AnalysisResult.condition == 'ë¶„ì„ë¶ˆê°€'
            ).all()
            
            for record in failed_analysis:
                db.session.delete(record)
                cleanup_results['deleted_records'] += 1
        
        elif cleanup_type == 'orphaned_images':
            # ë¶„ì„ ê²°ê³¼ê°€ ì—†ëŠ” ì´ë¯¸ì§€ ì‚­ì œ
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µìž¡í•œ ë¡œì§ í•„ìš”
            cleanup_results['deleted_records'] = 0  # ì‹œë®¬ë ˆì´ì…˜
        
        db.session.commit()
        
        # ì˜ˆìƒ ì ˆì•½ ê³µê°„ ê³„ì‚°
        cleanup_results['freed_space_kb'] = cleanup_results['deleted_records'] * 2 * 1024
        
        return jsonify({
            'status': 'success',
            'message': 'ë°ì´í„° ì •ë¦¬ ì™„ë£Œ',
            'data': cleanup_results
        }), 200
        
    except Exception as e:
        db.session.rollback()
        return jsonify({
            'status': 'error',
            'message': f'ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}'
        }), 500

@data_management_bp.route('/backup', methods=['POST'])
def create_backup():
    """ë°ì´í„° ë°±ì—… ìƒì„±"""
    try:
        backup_info = {
            'backup_id': f'backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
            'created_at': datetime.now().isoformat(),
            'status': 'completed',
            'records_count': {
                'analysis_results': AnalysisResult.query.count(),
                'environment_data': EnvironmentData.query.count(),
                'images': PlantImage.query.count()
            },
            'backup_size_mb': round(random.uniform(10, 100), 2),
            'backup_location': '/backups/smartfarm_backup.zip'
        }
        
        return jsonify({
            'status': 'success',
            'message': 'ë°±ì—…ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤',
            'data': backup_info
        }), 200
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': f'ë°±ì—… ìƒì„± ì‹¤íŒ¨: {str(e)}'
        }), 500 