import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import sqlite3
import json
import os
import pickle
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from cryptography.fernet import Fernet
import hashlib

class GlobalPlantModel(nn.Module):
    """ê¸€ë¡œë²Œ ê¸°ë³¸ ëª¨ë¸ - ëª¨ë“  ë†ê°€ ë°ì´í„°ë¡œ í•™ìŠµëœ ê¸°ë°˜ ëª¨ë¸"""
    
    def __init__(self, input_size=20, hidden_size=64):
        super().__init__()
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_size, 32),
            nn.ReLU(),
            nn.Linear(32, 16)
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, 5)  # ê±´ê°•ë„, í¬ê¸°, ë†’ì´, ìœ„í—˜ë„, ì„±ì¥ë¥ 
        )
    
    def forward(self, x):
        features = self.feature_extractor(x)
        output = self.classifier(features)
        return features, output

class PersonalizedLayer(nn.Module):
    """ë†ê°€ë³„ ê°œì¸í™” ë ˆì´ì–´"""
    
    def __init__(self, feature_size=16, output_size=5):
        super().__init__()
        self.adaptation_layer = nn.Sequential(
            nn.Linear(feature_size, 12),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(12, 8),
            nn.ReLU(),
            nn.Linear(8, output_size)
        )
    
    def forward(self, global_features):
        return self.adaptation_layer(global_features)

class FarmClusterModel(nn.Module):
    """ë†ê°€ í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹í™” ëª¨ë¸"""
    
    def __init__(self, cluster_type: str):
        super().__init__()
        self.cluster_type = cluster_type
        
        # í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹í™”ëœ ì•„í‚¤í…ì²˜
        if cluster_type == "smart_greenhouse":
            # ìŠ¤ë§ˆíŠ¸ ì˜¨ì‹¤: í™˜ê²½ ë°ì´í„° ì¤‘ì‹¬
            self.adjustment_layer = nn.Sequential(
                nn.Linear(16, 12),
                nn.ReLU(),
                nn.Linear(12, 5)
            )
        elif cluster_type == "traditional_greenhouse":
            # ì „í†µ ì˜¨ì‹¤: ì‹œê°ì  ë¶„ì„ ì¤‘ì‹¬
            self.adjustment_layer = nn.Sequential(
                nn.Linear(16, 10),
                nn.ReLU(),
                nn.Linear(10, 5)
            )
        else:  # open_field
            # ë…¸ì§€ ì¬ë°°: ê¸°ìƒ ë°ì´í„° ì¤‘ì‹¬
            self.adjustment_layer = nn.Sequential(
                nn.Linear(16, 14),
                nn.ReLU(),
                nn.Linear(14, 5)
            )
    
    def forward(self, features):
        return self.adjustment_layer(features)

class FederatedFarmAI:
    """ì—°í•©í•™ìŠµ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ë†ê°€ AI ì‹œìŠ¤í…œ"""
    
    def __init__(self, farm_id: str):
        self.farm_id = farm_id
        self.farm_hash = hashlib.md5(farm_id.encode()).hexdigest()[:8]
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        self.models_dir = "./models/federated"
        self.farm_models_dir = f"{self.models_dir}/farms"
        self.global_model_path = f"{self.models_dir}/global_model.pt"
        self.farm_model_path = f"{self.farm_models_dir}/{self.farm_hash}_personal.pt"
        self.farm_db_path = f"{self.farm_models_dir}/{self.farm_hash}_data.db"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.models_dir, exist_ok=True)
        os.makedirs(self.farm_models_dir, exist_ok=True)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.global_model = GlobalPlantModel()
        self.personal_layer = PersonalizedLayer()
        self.cluster_models = self._init_cluster_models()
        self.scaler = StandardScaler()
        
        # ë†ê°€ ì •ë³´
        self.farm_cluster = None
        self.training_data_count = 0
        
        # ì•”í˜¸í™” í‚¤ (í”„ë¼ì´ë²„ì‹œ ë³´ì¥)
        self.encryption_key = self._get_or_create_encryption_key()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_farm_database()
        
        # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ
        self._load_models()
    
    def _init_cluster_models(self) -> Dict[str, FarmClusterModel]:
        """í´ëŸ¬ìŠ¤í„°ë³„ ëª¨ë¸ ì´ˆê¸°í™”"""
        return {
            "smart_greenhouse": FarmClusterModel("smart_greenhouse"),
            "traditional_greenhouse": FarmClusterModel("traditional_greenhouse"),
            "open_field": FarmClusterModel("open_field")
        }
    
    def _get_or_create_encryption_key(self) -> Fernet:
        """ë†ê°€ë³„ ì•”í˜¸í™” í‚¤ ìƒì„±/ë¡œë“œ"""
        key_path = f"{self.farm_models_dir}/{self.farm_hash}_key.key"
        
        if os.path.exists(key_path):
            with open(key_path, 'rb') as f:
                key = f.read()
        else:
            key = Fernet.generate_key()
            with open(key_path, 'wb') as f:
                f.write(key)
        
        return Fernet(key)
    
    def _init_farm_database(self):
        """ë†ê°€ë³„ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.farm_db_path)
        cursor = conn.cursor()
        
        # í•™ìŠµ ë°ì´í„° í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS training_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME,
                plant_type TEXT,
                environment_data TEXT,
                image_features TEXT,
                analysis_result TEXT,
                user_feedback INTEGER,
                prediction_accuracy REAL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ë†ê°€ ë©”íƒ€ë°ì´í„° í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS farm_metadata (
                id INTEGER PRIMARY KEY,
                farm_id TEXT UNIQUE,
                cluster_type TEXT,
                facility_type TEXT,
                crop_types TEXT,
                location_info TEXT,
                experience_level INTEGER,
                last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ëª¨ë¸ ì„±ëŠ¥ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS model_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_version TEXT,
                global_accuracy REAL,
                personal_accuracy REAL,
                cluster_accuracy REAL,
                hybrid_accuracy REAL,
                training_samples INTEGER,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ì—°í•©í•™ìŠµ ê¸°ì—¬ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS federation_contributions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                contribution_hash TEXT,
                model_parameters_size INTEGER,
                privacy_noise_level REAL,
                contribution_date DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def classify_farm(self, farm_info: Dict) -> str:
        """ë†ê°€ ë¶„ë¥˜ ë° í´ëŸ¬ìŠ¤í„° í• ë‹¹"""
        # ë†ê°€ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜
        facility_type = farm_info.get('facility_type', 'greenhouse')
        automation_level = farm_info.get('automation_level', 'medium')
        crop_type = farm_info.get('crop_type', 'leafy_greens')
        
        # ë¶„ë¥˜ ë¡œì§
        if facility_type == 'smart_greenhouse' or automation_level == 'high':
            cluster = "smart_greenhouse"
        elif facility_type == 'greenhouse' or facility_type == 'tunnel':
            cluster = "traditional_greenhouse"
        else:
            cluster = "open_field"
        
        self.farm_cluster = cluster
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        self._save_farm_metadata(farm_info)
        
        return cluster
    
    def _save_farm_metadata(self, farm_info: Dict):
        """ë†ê°€ ë©”íƒ€ë°ì´í„° ì €ì¥"""
        conn = sqlite3.connect(self.farm_db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO farm_metadata 
            (farm_id, cluster_type, facility_type, crop_types, location_info, experience_level)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            self.farm_id,
            self.farm_cluster,
            farm_info.get('facility_type', 'unknown'),
            json.dumps(farm_info.get('crop_types', [])),
            json.dumps(farm_info.get('location_info', {})),
            farm_info.get('experience_level', 3)
        ))
        
        conn.commit()
        conn.close()
    
    def hybrid_predict(self, input_data: Dict, use_existing_ai: bool = True) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ - ê¸°ì¡´ AI + ì—°í•©í•™ìŠµ AI ê²°í•©"""
        
        # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
        processed_input = self._preprocess_input(input_data)
        input_tensor = torch.FloatTensor(processed_input).unsqueeze(0)
        
        predictions = {}
        
        # ê¸°ì¡´ AI ì‹œìŠ¤í…œ ì˜ˆì¸¡ (ì‹œë®¬ë ˆì´ì…˜)
        if use_existing_ai:
            # ê¸°ì¡´ AI ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜
            existing_result = {
                'overallScore': 75 + np.random.randint(-10, 15),
                'confidence': 80 + np.random.randint(-5, 15),
                'recommendations': [
                    "ë¬¼ ê³µê¸‰ëŸ‰ì„ 10% ì¦ê°€ì‹œí‚¤ì„¸ìš”.",
                    "í–‡ë¹› ë…¸ì¶œì„ ëŠ˜ë ¤ì£¼ì„¸ìš”.",
                    "ì˜¨ë„ë¥¼ 2ë„ ë‚®ì¶°ì£¼ì„¸ìš”."
                ]
            }
            
            predictions['existing_ai'] = {
                'health_score': existing_result.get('overallScore', 75),
                'confidence': existing_result.get('confidence', 80),
                'recommendations': existing_result.get('recommendations', []),
                'weight': 0.3  # ê¸°ì¡´ AI ê°€ì¤‘ì¹˜ 30%
            }
        
        # ì—°í•©í•™ìŠµ í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡
        if self.training_data_count >= 10:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ
            # 1ë‹¨ê³„: ê¸€ë¡œë²Œ ëª¨ë¸ ì˜ˆì¸¡
            with torch.no_grad():
                global_features, global_output = self.global_model(input_tensor)
            
            # 2ë‹¨ê³„: ê°œì¸í™” ë ˆì´ì–´ ì ìš©
            with torch.no_grad():
                personal_output = self.personal_layer(global_features)
            
            # 3ë‹¨ê³„: í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ë³´ì •
            cluster_output = None
            if self.farm_cluster and self.farm_cluster in self.cluster_models:
                with torch.no_grad():
                    cluster_output = self.cluster_models[self.farm_cluster](global_features)
            
            # í•˜ì´ë¸Œë¦¬ë“œ ê²°í•©
            if cluster_output is not None:
                # 3ë‹¨ê³„ ì•™ìƒë¸”
                hybrid_output = (
                    global_output * 0.4 +      # ê¸€ë¡œë²Œ 40%
                    personal_output * 0.4 +    # ê°œì¸í™” 40%
                    cluster_output * 0.2       # í´ëŸ¬ìŠ¤í„° 20%
                )
                confidence = 90
            else:
                # 2ë‹¨ê³„ ì•™ìƒë¸”
                hybrid_output = (
                    global_output * 0.6 +      # ê¸€ë¡œë²Œ 60%
                    personal_output * 0.4      # ê°œì¸í™” 40%
                )
                confidence = 85
            
            predictions['federated_ai'] = {
                'health_score': float(hybrid_output[0][0].item()),
                'predicted_size': float(hybrid_output[0][1].item()),
                'predicted_height': float(hybrid_output[0][2].item()),
                'risk_level': float(hybrid_output[0][3].item()),
                'growth_rate': float(hybrid_output[0][4].item()),
                'confidence': confidence,
                'is_personalized': True,
                'training_samples': self.training_data_count,
                'cluster_type': self.farm_cluster,
                'weight': 0.7  # ì—°í•©í•™ìŠµ AI ê°€ì¤‘ì¹˜ 70%
            }
        else:
            # ë°ì´í„° ë¶€ì¡±ì‹œ ê¸€ë¡œë²Œ ëª¨ë¸ë§Œ ì‚¬ìš©
            with torch.no_grad():
                global_features, global_output = self.global_model(input_tensor)
            
            predictions['federated_ai'] = {
                'health_score': float(global_output[0][0].item()),
                'predicted_size': float(global_output[0][1].item()),
                'predicted_height': float(global_output[0][2].item()),
                'risk_level': float(global_output[0][3].item()),
                'growth_rate': float(global_output[0][4].item()),
                'confidence': 70,
                'is_personalized': False,
                'training_samples': self.training_data_count,
                'message': f'ê°œì¸í™”ë¥¼ ìœ„í•´ {10 - self.training_data_count}ê°œ ë” í•„ìš”',
                'weight': 0.7
            }
        
        # ìµœì¢… ê²°í•© ì˜ˆì¸¡
        final_prediction = self._combine_predictions(predictions)
        
        return final_prediction
    
    def _combine_predictions(self, predictions: Dict) -> Dict[str, Any]:
        """ê¸°ì¡´ AIì™€ ì—°í•©í•™ìŠµ AI ì˜ˆì¸¡ ê²°í•©"""
        
        if 'existing_ai' in predictions and 'federated_ai' in predictions:
            existing = predictions['existing_ai']
            federated = predictions['federated_ai']
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            combined_health = (
                existing['health_score'] * existing['weight'] +
                federated['health_score'] * federated['weight']
            )
            
            combined_confidence = (
                existing['confidence'] * existing['weight'] +
                federated['confidence'] * federated['weight']
            )
            
            # ê¶Œì¥ì‚¬í•­ ê²°í•©
            combined_recommendations = existing.get('recommendations', [])
            if federated.get('is_personalized', False):
                combined_recommendations.append("ê°œì¸í™”ëœ AI ë¶„ì„ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            return {
                'hybrid_health_score': round(combined_health, 1),
                'hybrid_confidence': round(combined_confidence, 1),
                'existing_ai_result': existing,
                'federated_ai_result': federated,
                'combined_recommendations': combined_recommendations,
                'analysis_type': 'hybrid',
                'personalization_status': federated.get('is_personalized', False),
                'training_progress': f"{self.training_data_count}/10 minimum samples"
            }
        
        elif 'federated_ai' in predictions:
            return predictions['federated_ai']
        elif 'existing_ai' in predictions:
            return predictions['existing_ai']
        else:
            return {'error': 'No predictions available'}
    
    def add_training_data(self, input_data: Dict, actual_result: Dict, user_feedback: Optional[int] = None):
        """í•™ìŠµ ë°ì´í„° ì¶”ê°€"""
        
        # ë°ì´í„° ì•”í˜¸í™” ì €ì¥
        encrypted_env_data = self.encryption_key.encrypt(
            json.dumps(input_data.get('environment_data', {})).encode()
        )
        encrypted_image_features = self.encryption_key.encrypt(
            json.dumps(input_data.get('image_features', {})).encode()
        )
        
        conn = sqlite3.connect(self.farm_db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO training_data 
            (timestamp, plant_type, environment_data, image_features, analysis_result, user_feedback)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (
            datetime.now(),
            input_data.get('plant_type', 'unknown'),
            encrypted_env_data.decode(),
            encrypted_image_features.decode(),
            json.dumps(actual_result),
            user_feedback
        ))
        
        conn.commit()
        conn.close()
        
        self.training_data_count += 1
        
        # ìë™ ì¬í›ˆë ¨ ì¡°ê±´ í™•ì¸
        if self.training_data_count % 20 == 0:  # 20ê°œë§ˆë‹¤
            self._retrain_personal_model()
    
    def _preprocess_input(self, input_data: Dict) -> List[float]:
        """ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬"""
        env_data = input_data.get('environment_data', {})
        img_features = input_data.get('image_features', {})
        
        # í™˜ê²½ ë°ì´í„° íŠ¹ì„± (8ê°œ)
        env_features = [
            env_data.get('innerTemperature', 25.0),
            env_data.get('innerHumidity', 60.0),
            env_data.get('ph', 6.5),
            env_data.get('ec', 2.0),
            env_data.get('dissolvedOxygen', 7.0),
            env_data.get('solarRadiation', 400.0),
            env_data.get('outerTemperature', 22.0),
            env_data.get('rootZoneTemperature', 24.0)
        ]
        
        # ì´ë¯¸ì§€ íŠ¹ì„± (12ê°œ)
        img_color = img_features.get('color', {})
        img_shape = img_features.get('shape', {})
        
        image_features = [
            img_features.get('health_score', 75.0),
            img_color.get('greenness', 70.0),
            img_color.get('yellowing', 10.0),
            img_color.get('browning', 5.0),
            img_shape.get('leaf_count', 8),
            img_shape.get('total_area', 25000),
            img_features.get('image_quality', 80.0),
            0.0, 0.0, 0.0, 0.0, 0.0  # íŒ¨ë”©
        ]
        
        return env_features + image_features
    
    def _retrain_personal_model(self):
        """ê°œì¸í™” ëª¨ë¸ ì¬í›ˆë ¨"""
        print(f"ğŸ”„ ë†ê°€ {self.farm_id} ê°œì¸í™” ëª¨ë¸ ì¬í›ˆë ¨ ì‹œì‘...")
        
        # í•™ìŠµ ë°ì´í„° ë¡œë“œ
        training_data = self._load_encrypted_training_data()
        
        if len(training_data) < 10:
            print("í•™ìŠµ ë°ì´í„° ë¶€ì¡±")
            return
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        X, y = self._prepare_training_data(training_data)
        
        # ê°œì¸í™” ë ˆì´ì–´ í›ˆë ¨
        self._train_personal_layer(X, y)
        
        # ëª¨ë¸ ì €ì¥
        self._save_models()
        
        print(f"âœ… ê°œì¸í™” ëª¨ë¸ ì¬í›ˆë ¨ ì™„ë£Œ (ë°ì´í„°: {len(training_data)}ê°œ)")
    
    def _load_encrypted_training_data(self) -> List[Dict]:
        """ì•”í˜¸í™”ëœ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        conn = sqlite3.connect(self.farm_db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT plant_type, environment_data, image_features, analysis_result, user_feedback
            FROM training_data
            ORDER BY created_at DESC
            LIMIT 100
        ''')
        
        data = []
        for row in cursor.fetchall():
            try:
                # ë³µí˜¸í™”
                env_data = json.loads(
                    self.encryption_key.decrypt(row[1].encode()).decode()
                )
                img_features = json.loads(
                    self.encryption_key.decrypt(row[2].encode()).decode()
                )
                
                data.append({
                    'plant_type': row[0],
                    'environment_data': env_data,
                    'image_features': img_features,
                    'analysis_result': json.loads(row[3]),
                    'user_feedback': row[4]
                })
            except Exception as e:
                print(f"ë°ì´í„° ë³µí˜¸í™” ì‹¤íŒ¨: {e}")
                continue
        
        conn.close()
        return data
    
    def _prepare_training_data(self, training_data: List[Dict]):
        """í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬"""
        X_data = []
        y_data = []
        
        for data in training_data:
            # ì…ë ¥ íŠ¹ì„±
            input_features = self._preprocess_input(data)
            X_data.append(input_features)
            
            # íƒ€ê²Ÿ ê°’
            result = data['analysis_result']
            targets = [
                result.get('overallScore', 75),
                result.get('analysisData', {}).get('size', 20),
                result.get('analysisData', {}).get('height', 25),
                0.3,  # ìœ„í—˜ë„
                data.get('user_feedback', 3) * 20  # ì„±ì¥ë¥ 
            ]
            y_data.append(targets)
        
        X = torch.FloatTensor(X_data)
        y = torch.FloatTensor(y_data)
        
        return X, y
    
    def _train_personal_layer(self, X: torch.Tensor, y: torch.Tensor):
        """ê°œì¸í™” ë ˆì´ì–´ í›ˆë ¨"""
        optimizer = optim.Adam(self.personal_layer.parameters(), lr=0.001)
        criterion = nn.MSELoss()
        
        # ê¸€ë¡œë²Œ ëª¨ë¸ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
        with torch.no_grad():
            global_features, _ = self.global_model(X)
        
        # ê°œì¸í™” ë ˆì´ì–´ í›ˆë ¨
        for epoch in range(50):
            optimizer.zero_grad()
            personal_output = self.personal_layer(global_features)
            loss = criterion(personal_output, y)
            loss.backward()
            optimizer.step()
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch}, Loss: {loss.item():.4f}")
    
    def _load_models(self):
        """ì €ì¥ëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
        # ê¸€ë¡œë²Œ ëª¨ë¸ ë¡œë“œ
        if os.path.exists(self.global_model_path):
            try:
                self.global_model.load_state_dict(torch.load(self.global_model_path))
                print("âœ… ê¸€ë¡œë²Œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except:
                print("âš ï¸ ê¸€ë¡œë²Œ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
        
        # ê°œì¸í™” ëª¨ë¸ ë¡œë“œ
        if os.path.exists(self.farm_model_path):
            try:
                self.personal_layer.load_state_dict(torch.load(self.farm_model_path))
                print(f"âœ… ë†ê°€ {self.farm_hash} ê°œì¸í™” ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except:
                print("âš ï¸ ê°œì¸í™” ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©")
        
        # í›ˆë ¨ ë°ì´í„° ê°œìˆ˜ ë¡œë“œ
        if os.path.exists(self.farm_db_path):
            try:
                conn = sqlite3.connect(self.farm_db_path)
                cursor = conn.cursor()
                cursor.execute('SELECT COUNT(*) FROM training_data')
                self.training_data_count = cursor.fetchone()[0]
                conn.close()
            except:
                self.training_data_count = 0
    
    def _save_models(self):
        """ëª¨ë¸ë“¤ ì €ì¥"""
        # ê°œì¸í™” ëª¨ë¸ ì €ì¥
        torch.save(self.personal_layer.state_dict(), self.farm_model_path)
        print(f"ğŸ’¾ ë†ê°€ {self.farm_hash} ê°œì¸í™” ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
    
    def get_farm_analytics(self) -> Dict[str, Any]:
        """ë†ê°€ ë¶„ì„ í˜„í™©"""
        return {
            'farm_id': self.farm_id,
            'farm_hash': self.farm_hash,
            'cluster_type': self.farm_cluster,
            'training_data_count': self.training_data_count,
            'personalization_ready': self.training_data_count >= 10,
            'next_retrain_at': self.training_data_count + (20 - (self.training_data_count % 20)),
            'model_status': {
                'global_model': os.path.exists(self.global_model_path),
                'personal_model': os.path.exists(self.farm_model_path),
                'cluster_models': list(self.cluster_models.keys())
            }
        }

class FederationCoordinator:
    """ì—°í•©í•™ìŠµ ì½”ë””ë„¤ì´í„° - ì „ì²´ ì‹œìŠ¤í…œ ê´€ë¦¬"""
    
    def __init__(self):
        self.models_dir = "./models/federated"
        self.global_model_path = f"{self.models_dir}/global_model.pt"
        self.federation_db_path = f"{self.models_dir}/federation.db"
        
        os.makedirs(self.models_dir, exist_ok=True)
        
        self.global_model = GlobalPlantModel()
        self._init_federation_database()
    
    def _init_federation_database(self):
        """ì—°í•©í•™ìŠµ í†µê³„ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.federation_db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS global_model_versions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                version TEXT,
                participating_farms INTEGER,
                total_samples INTEGER,
                global_accuracy REAL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS farm_clusters (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                cluster_name TEXT,
                cluster_description TEXT,
                farm_count INTEGER,
                average_accuracy REAL,
                last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def aggregate_farm_models(self, farm_models: List[Dict]) -> bool:
        """ë†ê°€ ëª¨ë¸ë“¤ì„ ì§‘ê³„í•˜ì—¬ ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        try:
            print(f"ğŸ”„ {len(farm_models)}ê°œ ë†ê°€ ëª¨ë¸ ì§‘ê³„ ì‹œì‘...")
            
            # ì—°í•© í‰ê·  (Federated Averaging)
            aggregated_params = {}
            
            for param_name in self.global_model.state_dict().keys():
                param_sum = torch.zeros_like(self.global_model.state_dict()[param_name])
                
                for farm_model in farm_models:
                    if param_name in farm_model['parameters']:
                        param_sum += farm_model['parameters'][param_name]
                
                aggregated_params[param_name] = param_sum / len(farm_models)
            
            # ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸
            self.global_model.load_state_dict(aggregated_params)
            
            # ëª¨ë¸ ì €ì¥
            torch.save(self.global_model.state_dict(), self.global_model_path)
            
            print("âœ… ê¸€ë¡œë²Œ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì§‘ê³„ ì‹¤íŒ¨: {e}")
            return False
    
    def get_federation_status(self) -> Dict[str, Any]:
        """ì—°í•©í•™ìŠµ ì „ì²´ í˜„í™©"""
        conn = sqlite3.connect(self.federation_db_path)
        cursor = conn.cursor()
        
        # ìµœì‹  ê¸€ë¡œë²Œ ëª¨ë¸ ì •ë³´
        cursor.execute('''
            SELECT * FROM global_model_versions 
            ORDER BY created_at DESC LIMIT 1
        ''')
        latest_version = cursor.fetchone()
        
        # í´ëŸ¬ìŠ¤í„° ì •ë³´
        cursor.execute('SELECT * FROM farm_clusters')
        clusters = cursor.fetchall()
        
        conn.close()
        
        return {
            'global_model_version': latest_version[1] if latest_version else "v1.0",
            'participating_farms': latest_version[2] if latest_version else 0,
            'total_training_samples': latest_version[3] if latest_version else 0,
            'global_accuracy': latest_version[4] if latest_version else 0.0,
            'active_clusters': len(clusters),
            'federation_status': "active" if latest_version else "initializing"
        } 