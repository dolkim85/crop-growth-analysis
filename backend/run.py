from flask import Flask
from flask_cors import CORS
from app.routes.analyze import analyze_bp
from dotenv import load_dotenv
import os
import socket

load_dotenv()

app = Flask(__name__)
CORS(app)

app.config['UPLOAD_FOLDER'] = os.getenv("UPLOAD_FOLDER", "./uploads")
app.config['SECRET_KEY'] = os.getenv("SECRET_KEY", "default-secret-key")

# ë¸”ë£¨í”„ë¦°íŠ¸ ë“±ë¡
app.register_blueprint(analyze_bp)

def find_available_port(start_port=5000, max_attempts=10):
    """ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ë¥¼ ì°¾ëŠ” í•¨ìˆ˜"""
    ports_to_try = [5000, 5001, 5002, 8000, 8080, 3001]
    
    for port in ports_to_try:
        try:
            # í¬íŠ¸ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(1)
            result = sock.connect_ex(('localhost', port))
            sock.close()
            
            if result != 0:  # í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì´ ì•„ë‹˜
                return port
        except Exception:
            continue
    
    # ëª¨ë“  ì§€ì •ëœ í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì´ë©´ ë™ì ìœ¼ë¡œ í¬íŠ¸ ì°¾ê¸°
    for port in range(start_port, start_port + max_attempts):
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(1)
            result = sock.connect_ex(('localhost', port))
            sock.close()
            
            if result != 0:
                return port
        except Exception:
            continue
    
    return None

@app.route('/api/v1/models', methods=['GET'])
def get_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ AI ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    models = [
        {
            "id": "advanced-plant-ai-v2",
            "name": "ê³ ê¸‰ ì‹ë¬¼ ë¶„ì„ AI v2.0 (ì„œë²„)",
            "category": "ë¬´ë£Œ",
            "accuracy": "94%",
            "description": "OpenCVì™€ ë¨¸ì‹ ëŸ¬ë‹ì„ í™œìš©í•œ ê³ ì •ë°€ ì‹ë¬¼ ë¶„ì„ ëª¨ë¸ì…ë‹ˆë‹¤.",
            "provider": "Smart Farm AI Server",
            "features": ["ìƒ‰ìƒ ë¶„ì„", "í˜•íƒœ ë¶„ì„", "ì§ˆë³‘ ê°ì§€", "í™˜ê²½ ìµœì í™”"],
            "analysisItems": [
                {"id": "plantHealth", "name": "ì‹ë¬¼ ê±´ê°•ë„", "type": "number", "unit": "%"},
                {"id": "leafColor", "name": "ì ìƒ‰ìƒ ë¶„ì„", "type": "object", "unit": ""},
                {"id": "size", "name": "í¬ê¸° ì¶”ì •", "type": "number", "unit": "cm"},
                {"id": "leafCount", "name": "ì ê°œìˆ˜", "type": "number", "unit": "ê°œ"},
                {"id": "diseaseDetection", "name": "ì§ˆë³‘ ê°ì§€", "type": "object", "unit": ""},
                {"id": "maturityLevel", "name": "ì„±ìˆ™ë„", "type": "number", "unit": "%"},
                {"id": "growthRate", "name": "ì„±ì¥ë¥ ", "type": "number", "unit": "ì "}
            ]
        },
        {
            "id": "tensorflow-plant-server",
            "name": "TensorFlow ì‹ë¬¼ ë¶„ì„ ëª¨ë¸ (ì„œë²„)",
            "category": "í•™ìŠµAI",
            "accuracy": "97%",
            "description": "ë”¥ëŸ¬ë‹ ê¸°ë°˜ ì‹¤ì‹œê°„ í•™ìŠµ ê°€ëŠ¥í•œ ì‹ë¬¼ ë¶„ì„ ëª¨ë¸ì…ë‹ˆë‹¤.",
            "provider": "Smart Farm AI Server",
            "features": ["ë”¥ëŸ¬ë‹ ë¶„ì„", "ì‹¤ì‹œê°„ í•™ìŠµ", "ì •ë°€ ì§„ë‹¨", "ì˜ˆì¸¡ ë¶„ì„"],
            "analysisItems": [
                {"id": "plantHealth", "name": "ì‹ë¬¼ ê±´ê°•ë„", "type": "number", "unit": "%"},
                {"id": "diseaseDetection", "name": "ì§ˆë³‘/í•´ì¶© ê°ì§€", "type": "object", "unit": ""},
                {"id": "growthStage", "name": "ì„±ì¥ ë‹¨ê³„", "type": "string", "unit": ""},
                {"id": "maturityLevel", "name": "ì„±ìˆ™ë„ í‰ê°€", "type": "number", "unit": "%"},
                {"id": "environmentScore", "name": "í™˜ê²½ ì í•©ë„", "type": "number", "unit": "ì "},
                {"id": "predictedYield", "name": "ì˜ˆìƒ ìˆ˜í™•ëŸ‰", "type": "number", "unit": "kg"}
            ]
        }
    ]
    
    return {
        "status": "success",
        "data": models,
        "message": f"AI ëª¨ë¸ ëª©ë¡ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤."
    }

@app.route('/api/v1/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "success",
        "message": "AI ë°±ì—”ë“œ ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.",
        "version": "1.1.0-hybrid"
    }

if __name__ == "__main__":
    # ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ ì°¾ê¸°
    port = find_available_port()
    
    if port is None:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)
    
    print("\n" + "="*60)
    print("ğŸš€ ìŠ¤ë§ˆíŠ¸íŒœ AI ë°±ì—”ë“œ ì„œë²„ ì‹œì‘")
    print("="*60)
    print(f"ğŸ“¡ í¬íŠ¸: {port}")
    print(f"ğŸŒ URL: http://localhost:{port}")
    print(f"ğŸ”— API: http://localhost:{port}/api/v1/")
    print(f"ğŸ’¾ ì—…ë¡œë“œ í´ë”: {app.config['UPLOAD_FOLDER']}")
    print("="*60)
    print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:")
    print(f"   â€¢ GET  /api/v1/health   - ì„œë²„ ìƒíƒœ í™•ì¸")
    print(f"   â€¢ GET  /api/v1/models   - AI ëª¨ë¸ ëª©ë¡")
    print(f"   â€¢ POST /api/v1/analyze  - ì‹ë¬¼ ì´ë¯¸ì§€ ë¶„ì„")
    print("="*60)
    print("ğŸ”§ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ: í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë‹¤ì¤‘ í¬íŠ¸ ìë™ ê°ì§€")
    print("âš¡ ì—°ê²° ì‹¤íŒ¨ ì‹œ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ AIë¡œ ìë™ í´ë°±")
    print("="*60)
    
    try:
        app.run(debug=True, host="0.0.0.0", port=port)
    except Exception as e:
        print(f"âŒ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ ë‹¤ë¥¸ í¬íŠ¸ë¥¼ ì‹œë„í•˜ê±°ë‚˜ ì‹¤í–‰ ì¤‘ì¸ ì„œë²„ë¥¼ ì¢…ë£Œí•´ì£¼ì„¸ìš”.") 